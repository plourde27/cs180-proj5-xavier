<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>CS 180 Project 5</title>
        <link href="https://fonts.googleapis.com/css2?family=Kanit:wght@600&family=Montserrat&display=swap" rel="stylesheet">        <meta charset="utf-8">
        

    <style>
        body {
            font-family: 'Montserrat';
        }

        p {
            margin-left: 30px;
            margin-right: 30px;
            text-align: center;
        }

        figcaption {
            text-align: center;
            margin-left: -20px;
            margin-right: -20px;
        }

        figure {
            display: inline-block;
        }

        #title {
            text-align: center;
            font-size: 70px;
            font-family: 'Kanit';
            margin-bottom: -24px;
        }

        #subtitle {
            text-align: center;
            font-size: 24px;
            margin-bottom: 40px;
        }

        #section {
            font-family: 'Kanit';
            text-align: center;
            background-color: rgb(50, 170, 50, 0.2);
            padding-top: 5px;
            padding-bottom: 5px;
        }

        #subsection {
            font-family: 'Montserrat';
            text-align: center;
            background-color: rgb(50, 150, 250, 0.2);
            padding-top: 5px;
            padding-bottom: 5px;
        }

        #mag_small {
            width: 160px;
            height: 160px;
            margin-left: 10px;
            margin-right: 10px;
            display: inline-block;
        }

        #big_centered {
            width: 320px;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        #margin_placeholder {
            margin-left: calc(50% - 510px);
        }
    </style>
    </head>
    <body>
        <h1 id="title">CS 180 PROJECT 5</h1>
        <h1 id="subtitle">Xavier Plourde</div>
        <h1 id="section">Project Overview</h1>
        <p>This project involved using a pre-trained diffusion model to produce many interesting images - for example, inpainting, hybrid images, and optical illusions.</p>
        <p>After that, the second part of the project involved creating a diffusion model from scratch using a complex architecture of convolutional layers, max pooling layers, and other things, which was used to train on and randomly sample MNIST digits.</p>
        <h1 id="section">Part A - 0 - Setup</h1>
        <h2 id="subsection">Overview</h2>
        <p>First, I tested the pre-trained diffusion model by generating a few images and varying the num_inferences parameter.</p>
        <p>Shown below are selected results for a few values of num_inferences. Notice how as num_inferences increases, the quality of the images increases significantly.</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 390px);">
            <img width=200 src="imgs/A0a.png">
            <figcaption><em>Amalfi Coast (num_inferences=10)</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A0b.png">
            <figcaption><em>Old Man (num_inferences=10)</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A0c.png">
            <figcaption><em>High-Quality Photo (num_inferences=10)</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 390px);">
            <img width=200 src="imgs/A0d.png">
            <figcaption><em>Amalfi Coast (num_inferences=20)</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A0e.png">
            <figcaption><em>Old Man (num_inferences=20)</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A0f.png">
            <figcaption><em>High-Quality Photo (num_inferences=20)</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 390px);">
            <img width=200 src="imgs/A0g.png">
            <figcaption><em>Amalfi Coast (num_inferences=50)</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A0h.png">
            <figcaption><em>Old Man (num_inferences=50)</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A0i.png">
            <figcaption><em>High-Quality Photo (num_inferences=50)</em></figcaption>
        </figure>
        <h1 id="section">Part A - 1.1 - Implementing the Forward Process</h1>
        <h2 id="subsection">Overview</h2>
        <p>After testing out the pre-trained diffusion model, I implemented the forward process for adding appropriate noise to the image. Specifically, I did this by generating a random image using torch.randn_like, and adding this multiplied by a factor between 0 and 1 to the original image</h2>
        <p>Shown below are the results for no noise, t=250, t=500, and t=750 (the t values control the noise factor based on the pre-computed alphas_cumprod list)</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 530px);">
            <img width=200 src="imgs/A1.3a.png">
            <figcaption><em>Campanile with no noise</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.1a.png">
            <figcaption><em>Campanile with noise level 250</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.1b.png">
            <figcaption><em>Campanile with noise level 500</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.1c.png">
            <figcaption><em>Campanile with noise level 750</em></figcaption>
        </figure>
        <h1 id="section">Part A - 1.2 - Classical Denoising</h1>
        <h2 id="subsection">Overview</h2>
        <p>After this, I implemented classical denoising using the torchvision.transforms.functional.gaussian_blur with a kernel size of 7 to blur the noise out of the image.</h2>
        <p>The results for this were not very good, especially for high levels of noise, and were meant more as a baseline for future, improved denoising techniques.</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 390px);">
            <img width=200 src="imgs/A1.2a.png">
            <figcaption><em>Campanile with noise level 250<br>with Gaussian de-noising</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.2b.png">
            <figcaption><em>Campanile with noise level 500<br>with Gaussian de-noising</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.2c.png">
            <figcaption><em>Campanile with noise level 750<br>with Gaussian de-noising</em></figcaption>
        </figure>
        <h1 id="section">Part A - 1.3 - One-Step Denoising</h1>
        <h2 id="subsection">Overview</h2>
        <p>Next, I implemented one-step denoising by passing in the noisy image to the pre-trained UNet model. This model predicts the nosie in an image, and we can recover the original image by subtracting this noise estimate from the noisy image, subject to some multiplicative factors that depend on the pre-computed alphas_cumprod list.</p>
        <p>The results for this, as seen below, were significantly better than that of classical denoising.</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 390px);">
            <img width=200 src="imgs/A1.1a.png">
            <figcaption><em>Campanile with noise level 250</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.1b.png">
            <figcaption><em>Campanile with noise level 500</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.1c.png">
            <figcaption><em>Campanile with noise level 750</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 390px);">
            <img width=200 src="imgs/A1.3b.png">
            <figcaption><em>Campanile with noise level 250<br>with One-Step de-noising</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.3c.png">
            <figcaption><em>Campanile with noise level 500<br>with One-Step de-noising</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.3d.png">
            <figcaption><em>Campanile with noise level 750<br>with One-Step de-noising</em></figcaption>
        </figure>
        <h1 id="section">Part A - 1.4 - Iterative Denoising</h1>
        <h2 id="subsection">Overview</h2>
        <p>After doing One-Step Denoising, I improved this by performing iterative denoising. For a given value of t, I run the pre-trained UNet to get the current noise prediction. There are too many values of t for denoising every single step to be practical, so instead, I step through every 30 values of t, using an interpolation formula to compute the current image at every iteration, which will progressively get less noisy as t gets lower. Shown below are some intermediate results of denoising the Campanile using this method, starting with a noise value determined by t=690, as well as the final results compared to methods used earlier. Notice how much better iterative denoising is compared to the alternatives.</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 540px);">
            <img width=150 src="imgs/A1.4e.png">
            <figcaption><em>Iteratively denoised<br>Campanile with<br>noise level 90</em></figcaption>
        </figure>
        <figure>
            <img width=150 src="imgs/A1.4d.png">
            <figcaption><em>Iteratively denoised<br>Campanile with<br>noise level 240</em></figcaption>
        </figure>
        <figure>
            <img width=150 src="imgs/A1.4c.png">
            <figcaption><em>Iteratively denoised<br>Campanile with<br>noise level 390</em></figcaption>
        </figure>
        <figure>
            <img width=150 src="imgs/A1.4b.png">
            <figcaption><em>Iteratively denoised<br>Campanile with<br>noise level 540</em></figcaption>
        </figure>
        <figure>
            <img width=150 src="imgs/A1.4a.png">
            <figcaption><em>Iteratively denoised<br>Campanile with<br>noise level 690</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 530px);">
            <img width=200 src="imgs/A1.4f.png">
            <figcaption><em>Original<br>Campanile</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.4g.png">
            <figcaption><em>Campanile denoised with<br>Gaussian blurring</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.4h.png">
            <figcaption><em>Campanile after<br>One-Step Denoising</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.4i.png">
            <figcaption><em>Campanile after<br>Iterative Denoising</em></figcaption>
        </figure>
        <h1 id="section">Part A - 1.5 - Diffusion Model Sampling</h1>
        <h2 id="subsection">Overview</h2>
        <p>From here, to generate randomly sampled images, I simply perform the iterative denoising process from an image of pure noise. 5 results of calling this sample function are shown below:</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 540px);">
            <img width=150 src="imgs/A1.5a.png">
            <figcaption><em>Sample 1</em></figcaption>
        </figure>
        <figure>
            <img width=150 src="imgs/A1.5b.png">
            <figcaption><em>Sample 2</em></figcaption>
        </figure>
        <figure>
            <img width=150 src="imgs/A1.5c.png">
            <figcaption><em>Sample 3</em></figcaption>
        </figure>
        <figure>
            <img width=150 src="imgs/A1.5d.png">
            <figcaption><em>Sample 4</em></figcaption>
        </figure>
        <figure>
            <img width=150 src="imgs/A1.5e.png">
            <figcaption><em>Sample 5</em></figcaption>
        </figure>
        <h1 id="section">Part A - 1.6 - Classifier-Free Guidance</h1>
        <h2 id="subsection">Overview</h2>
        <p>To improve the sampling results, I added classifier-free guidance: by adding to the noise estimate an extra term of gamma * (noise - unconditional noise), where gamma=7 here and unconditional noise is the noise calculated by running the UNet on an empty prompt. This improved the results, as seen below for another 5 random samples:</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 540px);">
            <img width=150 src="imgs/A1.6a.png">
            <figcaption><em>Sample 1</em></figcaption>
        </figure>
        <figure>
            <img width=150 src="imgs/A1.6b.png">
            <figcaption><em>Sample 2</em></figcaption>
        </figure>
        <figure>
            <img width=150 src="imgs/A1.6c.png">
            <figcaption><em>Sample 3</em></figcaption>
        </figure>
        <figure>
            <img width=150 src="imgs/A1.6d.png">
            <figcaption><em>Sample 4</em></figcaption>
        </figure>
        <figure>
            <img width=150 src="imgs/A1.6e.png">
            <figcaption><em>Sample 5</em></figcaption>
        </figure>
        <h1 id="section">Part A - 1.7 - Image-to-image Translation</h1>
        <h2 id="subsection">Overview</h2>
        <p>Using this sampling algorithm, we can generate sample images that progressively look more and more similar to the test image, by starting at values of t other than pure noise. Shown below is this process applied to three images: the Campanile; a photo of my family's cat, Miso; and a photo of myself. From left to right, notice how the images gradually get more and more similar to each test image.</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 635px);">
            <img width=110 src="imgs/A1.7o.png">
            <figcaption><em style="font-size: 9px;">SDEdit on Image of Campanile<br>with i_start=1</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7p.png">
            <figcaption><em style="font-size: 9px;">SDEdit on Image of Campanile<br>with i_start=3</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7q.png">
            <figcaption><em style="font-size: 9px;">SDEdit on Image of Campanile<br>with i_start=5</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7r.png">
            <figcaption><em style="font-size: 9px;">SDEdit on Image of Campanile<br>with i_start=7</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7s.png">
            <figcaption><em style="font-size: 9px;">SDEdit on Image of Campanile<br>with i_start=10</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7t.png">
            <figcaption><em style="font-size: 9px;">SDEdit on Image of Campanile<br>with i_start=20</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7u.png">
            <figcaption><em style="font-size: 9px;">Original Image<br>of Campanile</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 635px);">
            <img width=110 src="imgs/A1.7a.png">
            <figcaption><em style="font-size: 10px;">SDEdit on Image of Miso<br>with i_start=1</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7b.png">
            <figcaption><em style="font-size: 10px;">SDEdit on Image of Miso<br>with i_start=3</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7c.png">
            <figcaption><em style="font-size: 10px;">SDEdit on Image of Miso<br>with i_start=5</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7d.png">
            <figcaption><em style="font-size: 10px;">SDEdit on Image of Miso<br>with i_start=7</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7e.png">
            <figcaption><em style="font-size: 10px;">SDEdit on Image of Miso<br>with i_start=10</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7f.png">
            <figcaption><em style="font-size: 10px;">SDEdit on Image of Miso<br>with i_start=20</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7g.png">
            <figcaption><em style="font-size: 10px;">Original Image<br>of Miso</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 635px);">
            <img width=110 src="imgs/A1.7h.png">
            <figcaption><em style="font-size: 10px;">SDEdit on Image of Xavier<br>with i_start=1</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7i.png">
            <figcaption><em style="font-size: 10px;">SDEdit on Image of Xavier<br>with i_start=3</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7j.png">
            <figcaption><em style="font-size: 10px;">SDEdit on Image of Xavier<br>with i_start=5</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7k.png">
            <figcaption><em style="font-size: 10px;">SDEdit on Image of Xavier<br>with i_start=7</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7l.png">
            <figcaption><em style="font-size: 10px;">SDEdit on Image of Xavier<br>with i_start=10</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7m.png">
            <figcaption><em style="font-size: 10px;">SDEdit on Image of Xavier<br>with i_start=20</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7n.png">
            <figcaption><em style="font-size: 10px;">Original Image<br>of Xavier</em></figcaption>
        </figure>
        <h1 id="section">Part A - 1.7.1 - Editing Hand-Drawn and Web Images</h1>
        <h2 id="subsection">Overview</h2>
        <p>This process works well when applied to hand-drawn images, in addition to just regular images. Shown below is the same process applied to three new images: an illustration from the web of Mt. Rainier, and crude drawings I made of a tree and of a diver, respectively.</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 635px);">
            <img width=110 src="imgs/A1.7.1a.png">
            <figcaption><em style="font-size: 10px;">Mt. Rainier<br>with i_start=1</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1b.png">
            <figcaption><em style="font-size: 10px;">Mt. Rainier<br>with i_start=3</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1c.png">
            <figcaption><em style="font-size: 10px;">Mt. Rainier<br>with i_start=5</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1d.png">
            <figcaption><em style="font-size: 10px;">Mt. Rainier<br>with i_start=7</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1e.png">
            <figcaption><em style="font-size: 10px;">Mt. Rainier<br>with i_start=10</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1f.png">
            <figcaption><em style="font-size: 10px;">Mt. Rainier<br>with i_start=20</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1g.png">
            <figcaption><em style="font-size: 10px;">Original Mt. Rainier<br>Drawing</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 635px);">
            <img width=110 src="imgs/A1.7.1h.png">
            <figcaption><em style="font-size: 10px;">Tree Drawing<br>with i_start=1</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1i.png">
            <figcaption><em style="font-size: 10px;">Tree Drawing<br>with i_start=3</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1j.png">
            <figcaption><em style="font-size: 10px;">Tree Drawing<br>with i_start=5</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1k.png">
            <figcaption><em style="font-size: 10px;">Tree Drawing<br>with i_start=7</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1l.png">
            <figcaption><em style="font-size: 10px;">Tree Drawing<br>with i_start=10</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1m.png">
            <figcaption><em style="font-size: 10px;">Tree Drawing<br>with i_start=20</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1n.png">
            <figcaption><em style="font-size: 10px;">Original Tree<br>Drawing</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 635px);">
            <img width=110 src="imgs/A1.7.1o.png">
            <figcaption><em style="font-size: 10px;">Diver Drawing<br>with i_start=1</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1p.png">
            <figcaption><em style="font-size: 10px;">Diver Drawing<br>with i_start=3</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1q.png">
            <figcaption><em style="font-size: 10px;">Diver Drawing<br>with i_start=5</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1r.png">
            <figcaption><em style="font-size: 10px;">Diver Drawing<br>with i_start=7</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1s.png">
            <figcaption><em style="font-size: 10px;">Diver Drawing<br>with i_start=10</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1t.png">
            <figcaption><em style="font-size: 10px;">Diver Drawing<br>with i_start=20</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.1u.png">
            <figcaption><em style="font-size: 10px;">Original Diver<br>Drawing</em></figcaption>
        </figure>
        <h1 id="section">Part A - 1.7.2 - Inpainting</h1>
        <h2 id="subsection">Overview</h2>
        <p>We can also apply this technique to inpainting images - where we take a test image, create a mask, blur out the mask from the test image, and denoise the image separately for the masked section and the rest of the image, producing a guess as to what the masked portion originally contained. I tried this on the Campanile image (masking the tip of the tower), the image of Miso (masking his head), and the image of myself (masking my head), with results shown below:</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 530px);">
            <img width=200 src="imgs/A1.7.2a.png">
            <figcaption><em>Campanile</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.7.2b.png">
            <figcaption><em>Campanile mask</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.7.2c.png">
            <figcaption><em>Campanile image hole to fill</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.7.2d.png">
            <figcaption><em>Inpainted Campanile</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 530px);">
            <img width=200 src="imgs/A1.7.2e.png">
            <figcaption><em>Xavier</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.7.2f.png">
            <figcaption><em>Xavier mask</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.7.2g.png">
            <figcaption><em>Xavier image hole to fill</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.7.2h.png">
            <figcaption><em>Inpainted Xavier Image</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 530px);">
            <img width=200 src="imgs/A1.7.2i.png">
            <figcaption><em>Miso</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.7.2j.png">
            <figcaption><em>Miso mask</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.7.2k.png">
            <figcaption><em>Miso image hole to fill</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/A1.7.2l.png">
            <figcaption><em>Inpainted Miso Image</em></figcaption>
        </figure>
        <h1 id="section">Part A - 1.7.3 - Text-conditional Image-to-image Translation</h1>
        <h2 id="subsection">Overview</h2>
        <p>As one last modification to the CFG algorithm from 1.6: we can apply a similar technique to 1.7, where we sample images with different i_start values; however, this time, I used other prompts than "a high quality photo". That way, an image will start out looking like the prompt, and gradually become more similar to the test image. Specifically, I first tried "a photo of the amalfi coast" as the prompt and the Campanile as the test image. Next, I tried "an oil painting of an old man" and the photo of myself, producing some funny results near the end. Finally, I tried "a photo of the amalfi coast" once again as the prompt, this time using a photo I took of the Salmon River Reservoir as the test image.</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 635px);">
            <img width=110 src="imgs/A1.7.3b.png">
            <figcaption><em style="font-size: 10px;">Amalfi Coast<br>with i_start=1</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3c.png">
            <figcaption><em style="font-size: 10px;">Amalfi Coast<br>with i_start=3</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3d.png">
            <figcaption><em style="font-size: 10px;">Amalfi Coast<br>with i_start=5</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3e.png">
            <figcaption><em style="font-size: 10px;">Amalfi Coast<br>with i_start=7</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3f.png">
            <figcaption><em style="font-size: 10px;">Amalfi Coast<br>with i_start=10</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3g.png">
            <figcaption><em style="font-size: 10px;">Amalfi Coast<br>with i_start=20</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3a.png">
            <figcaption><em style="font-size: 10px;">Campanile<br>Image</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 635px);">
            <img width=110 src="imgs/A1.7.3i.png">
            <figcaption><em style="font-size: 10px;">Old Man<br>with i_start=1</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3j.png">
            <figcaption><em style="font-size: 10px;">Old Man<br>with i_start=3</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3k.png">
            <figcaption><em style="font-size: 10px;">Old Man<br>with i_start=5</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3l.png">
            <figcaption><em style="font-size: 10px;">Old Man<br>with i_start=7</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3m.png">
            <figcaption><em style="font-size: 10px;">Old Man<br>with i_start=10</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3n.png">
            <figcaption><em style="font-size: 10px;">Old Man<br>with i_start=20</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3h.png">
            <figcaption><em style="font-size: 10px;">Original Xavier<br>Image</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 635px);">
            <img width=110 src="imgs/A1.7.3p.png">
            <figcaption><em style="font-size: 10px;">Amalfi Coast<br>with i_start=1</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3q.png">
            <figcaption><em style="font-size: 10px;">Amalfi Coast<br>with i_start=3</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3r.png">
            <figcaption><em style="font-size: 10px;">Amalfi Coast<br>with i_start=5</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3s.png">
            <figcaption><em style="font-size: 10px;">Amalfi Coast<br>with i_start=7</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3t.png">
            <figcaption><em style="font-size: 10px;">Amalfi Coast<br>with i_start=10</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3u.png">
            <figcaption><em style="font-size: 10px;">Amalfi Coast<br>with i_start=20</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/A1.7.3o.png">
            <figcaption><em style="font-size: 10px;">Original Salmon<br>River Image</em></figcaption>
        </figure>
        <h1 id="section">Part A - 1.8 - Visual Anagrams</h1>
        <h2 id="subsection">Overview</h2>
        <p>Next, I applied the methods of the CFG sampling algorithm to solve a more difficult problem: sampling visual anagrams; specifically, generating an image that looked like one prompt right side up, and another prompt upside down.</p>
        <p>I accomplished this by generating two noise estimates: one for the regular image with the first prompt, and the other of the flipped image with the second prompt, flipping the result of the latter noise estimate. Doing this for both the conditional and unconditional noise estimates and averaging each of the results for the two prompts together, I proceed with the CFG algorithm as normal, performing this modified process on every iteration.</p>
        <p>I tried this on three image pairs, having to try a lot of different samples for each before finding a reasonable result. First, I reproduced the assignment image of an old man and people around a campfire. Then, I made an image that looked like Mt. Rainier when looked at right side up, and looked like a huge ship when looked at upside down. Finally, I made an image that also looked like Mt. Rainier when shown right side up, but looked like a bowl of pasta when shown upside-down. Results are shown below:</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 380px);">
            <img width=300 src="imgs/A1.8a.png">
            <figcaption><em>An Oil Painting<br>of an Old Man</em></figcaption>
        </figure>
        <figure>
            <img width=300 style="transform: scaleY(-1);" src="imgs/A1.8a.png">
            <figcaption><em>An Oil Painting<br>of People Around a Campfire</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 380px);">
            <img width=300 src="imgs/A1.8b.png">
            <figcaption><em>A Photo<br>of Mt. Rainier</em></figcaption>
        </figure>
        <figure>
            <img width=300 style="transform: scaleY(-1);" src="imgs/A1.8b.png">
            <figcaption><em>A Photo<br>of a Huge Ship</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 380px);">
            <img width=300 src="imgs/A1.8c.png">
            <figcaption><em>A Photo<br>of Mt. Rainier</em></figcaption>
        </figure>
        <figure>
            <img width=300 style="transform: scaleY(-1);" src="imgs/A1.8c.png">
            <figcaption><em>A Photo<br>of a Bowl of Pasta</em></figcaption>
        </figure>
        <h1 id="section">Part A - 1.9 - Hybrid Images</h1>
        <h2 id="subsection">Overview</h2>
        <p>For the final task of Part A, I used a similar technique to the previous section to generate hybrid images: images that looked like one thing close up, and another thing far away.</p>
        <p>I accomplished this in a similar manner to the visual anagrams, except that I didn't flip the images this time, and instead of just averaging the noise values, I applied a low-pass filter to one, and a high-pass filter to the other.</p>
        <p>I applied this to three image pairs: a hybrid image of a skull and a waterfall like the example from the project description, a hybrid image of Mt. Rainier and a rocket ship, and finally, a hybrid imgae of a man wearing a hat and a rocket ship.
        </p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 200px);">
            <img width=400 src="imgs/A1.9a.png">
            <figcaption><em>A hybrid image of a Skull<br>and a Waterfall</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 200px);">
            <img width=400 src="imgs/A1.9b.png">
            <figcaption><em>A hybrid image of Mt. Rainier<br>and a Rocket Ship</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 200px);">
            <img width=400 src="imgs/A1.9c.png">
            <figcaption><em>A hybrid image of a Man Wearing a hat<br>and a Rocket Ship</em></figcaption>
        </figure>
        <h1 id="section">Part B - 1 - Training a Single-Step Denoising UNet</h1>
        <h2 id="subsection">Overview</h2>
        <p>After using the pre-trained DeepFloyd model in Part A, in Part B, I set out to train my own UNet and use this to sample MNIST digits.</p>
        <p>I started by applying noise to MNIST digits with varying levels, as shown in the first image.</p>
        <p>Then, I used various torch.nn modules to construct a full UNet for single-step denoising, training this UNet on MNIST data with partial (0.5) noise applied to them.</p>
        <p>After training for 5 epochs using the L2 loss between the predicted image and the real image, my model achieved reasonably low loss, and successfully recovered the original, noiseless digits for several examples shown below.</p>
        <p>Lastly, I tried denoising images with different noise values (i.e. not just 0.5) using my UNet, with varying results, also shown below.</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 350px);">
            <img width=700 src="imgs/B1.1a.png">
            <figcaption><em>Noising processes applied to various images<br>with noise levels of [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0] from left to right</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 300px);">
            <img width=600 src="imgs/B1.1b.png">
            <figcaption><em>Single-Step UNet Training Loss</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 390px);">
            <img width=200 src="imgs/B1.1c.png">
            <figcaption><em>Input</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/B1.1d.png">
            <figcaption><em>Noise (0.5)</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/B1.1e.png">
            <figcaption><em>Output (Epoch 1)</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 390px);">
            <img width=200 src="imgs/B1.1f.png">
            <figcaption><em>Input</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/B1.1g.png">
            <figcaption><em>Noise (0.5)</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/B1.1h.png">
            <figcaption><em>Output (Epoch 1)</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 390px);">
            <img width=200 src="imgs/B1.1i.png">
            <figcaption><em>Input</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/B1.1j.png">
            <figcaption><em>Noise (0.5)</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/B1.1k.png">
            <figcaption><em>Output (Epoch 1)</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 390px);">
            <img width=200 src="imgs/B1.1l.png">
            <figcaption><em>Input</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/B1.1m.png">
            <figcaption><em>Noise (0.5)</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/B1.1n.png">
            <figcaption><em>Output (Epoch 5)</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 390px);">
            <img width=200 src="imgs/B1.1o.png">
            <figcaption><em>Input</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/B1.1p.png">
            <figcaption><em>Noise (0.5)</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/B1.1q.png">
            <figcaption><em>Output (Epoch 5)</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 390px);">
            <img width=200 src="imgs/B1.1r.png">
            <figcaption><em>Input</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/B1.1s.png">
            <figcaption><em>Noise (0.5)</em></figcaption>
        </figure>
        <figure>
            <img width=200 src="imgs/B1.1t.png">
            <figcaption><em>Output (Epoch 5)</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 635px);">
            <img width=110 src="imgs/B1.1u.png">
            <figcaption><em style="font-size: 10px;">Noise=0.0</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/B1.1w.png">
            <figcaption><em style="font-size: 10px;">Noise=0.2</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/B1.1y.png">
            <figcaption><em style="font-size: 10px;">Noise=0.4</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/B1.1aa.png">
            <figcaption><em style="font-size: 10px;">Noise=0.5</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/B1.1cc.png">
            <figcaption><em style="font-size: 10px;">Noise=0.6</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/B1.1ee.png">
            <figcaption><em style="font-size: 10px;">Noise=0.8</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/B1.1gg.png">
            <figcaption><em style="font-size: 10px;">Noise=1.0</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 635px);">
            <img width=110 src="imgs/B1.1v.png">
            <figcaption><em style="font-size: 10px;">Denoised Image</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/B1.1x.png">
            <figcaption><em style="font-size: 10px;">Denoised Image</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/B1.1z.png">
            <figcaption><em style="font-size: 10px;">Denoised Image</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/B1.1bb.png">
            <figcaption><em style="font-size: 10px;">Denoised Image</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/B1.1dd.png">
            <figcaption><em style="font-size: 10px;">Denoised Image</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/B1.1ff.png">
            <figcaption><em style="font-size: 10px;">Denoised Image</em></figcaption>
        </figure>
        <figure>
            <img width=110 src="imgs/B1.1hh.png">
            <figcaption><em style="font-size: 10px;">Denoised Image</em></figcaption>
        </figure>
        <h1 id="section">Part B - 2.1-2.3 - Training a Diffusion Model (No Class-Conditioning)</h1>
        <h2 id="subsection">Overview</h2>
        <p>After successfully training a single-step denoising model, I proceeded to train a time-conditioned model to be able to produce sample MNIST digits from completely random noise.</p>
        <p>I accomplished this by adding two FCBlock network layers to the model, each of which takes in t as a parameter. I also modified the training of the algorithm to predict the noise added instead of the original image.</p>
        <p>After this, I ran a similar algorithm to my algorithm from part A1.4 with the pre-trained UNet, generating random MNIST digits. Although the loss curve jumped around a bit, the actual image results, shown below for epochs 5 and 20, were promising.</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 300px);">
            <img width=600 src="imgs/B2.1a.png">
            <figcaption><em>Diffusion Model (No Class-Conditioning) UNet Training Loss</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 300px);">
            <img width=600 src="imgs/B2.1c.png">
            <figcaption><em>Results after 5 Epochs</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 300px);">
            <img width=600 src="imgs/B2.1b.png">
            <figcaption><em>Results after 20 Epochs</em></figcaption>
        </figure>
        <h1 id="section">Part B - 2.4-2.5 - Training a Diffusion Model (With Class-Conditioning)</h1>
        <h2 id="subsection">Overview</h2>
        <p>Finally, I added class condition to the model from earlier, in order to generate random samples of specific digits. I did this by adding an additional parameter, c, to the forward function - a one-hot encoding of the digit to generate a sample of. I conditioned the model based on this parameter by multiplying two of the intermediate values by this c parameter, in the same place where I add the FCBlock applied to t.</p>
        <p>This once again produced a somewhat funky loss curve, but the results looked good for every digit - shown below for epochs 5 and 30.</p>
        <h2 id="subsection">Results</h2>
        <figure style="margin-left: calc(50% - 300px);">
            <img width=600 src="imgs/B2.2a.png">
            <figcaption><em>Diffusion Model (With Class-Conditioning) UNet Training Loss</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 300px);">
            <img width=600 src="imgs/B2.2c.png">
            <figcaption><em>Results after 5 Epochs</em></figcaption>
        </figure>
        <br>
        <figure style="margin-left: calc(50% - 300px);">
            <img width=600 src="imgs/B2.2b.png">
            <figcaption><em>Results after 30 Epochs</em></figcaption>
        </figure>
        <h1 id="section">Conclusion</h1>
        <p>Overall this was a very interesting project and I had a lot of fun both playing around with pre-trained diffusion models, and training my own diffusion models. The biggest thing I learned from this project was to try running a sample multiple times if the first time didn't quite look right; especially, for parts A1.8 and A1.9 where the model was not specifically trained for the task at hand.</p>

    </body>

    <script>
    </script>
</html>

